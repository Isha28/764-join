# vi:ts=2

path:	"datagen/";
bucksize:	1048576 ;  #this bucksize is the size of each tuplebuffer in the in-memory build and probe tables

partitioner:
{
	build:
	{
		algorithm:	"parallel";
		#this is the size of each tuplebuffer for the partitioned inputs. 
		#it's set such that buckets*pagesize = 268,435,456 (=256M = size of larger table?) 
		#Reason is not clear to me
		pagesize:	134217728;  
		attribute:	1;
	};

	probe:
	{
		algorithm:	"parallel";
		pagesize:	134217728;
		attribute:	2;
	};

	hash:
	{
		fn:			"modulo";
		range:		[1,16777216];  #this is 16*1024*1024 = number of tuples in build table
		buckets:	2048;
		skipbits:	12;
	};
};

build:
{
	file: 	"016M_build.tbl";
	schema: ("long", "long", "long");
	jattr:	1;
	select:	(2,3);
};

probe:
{
	file:	"256M_probe.tbl";
	schema:	("long","long", "long");
	jattr:	2;
	select:	(1,3);
};

output:	"test.tbl";

hash:
{
	fn:			"modulo";
	range:		[1,16777216];
	buckets:	8388608;
};

algorithm:
{
	copydata:		"yes";
	partitionbuild:	"yes";
	buildpagesize:  32;
	partitionprobe:	"yes";
};

threads:	20;
